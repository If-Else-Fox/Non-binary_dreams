23 июня 2025 года

	Началось все с того, что в моей голове промелькнула мысль о том, что бинарная логика, по сути, себя изжила. И ведь правда: «0 или 1» / «да или нет» - основа первых компьютеров и классической логической мысли - в современных реалиях вытесняется нечеткой логикой, предполагающей вероятность принадлежности («это не абсолютно чёрное или белое, а оттенки серого»), многозначная логика, в которой, кроме True/False, есть и промежуточные состояния, а также искусственные нейросети и модели машинного обучения, исключающие чёткое бинарное деление и оперирующие весовыми коэффициентами, паттернами и статистическими данными.

	Я решил пойти следующим путем: придумать систему, в которой каждое состояние может иметь не два (0 или 1), а несколько значений — для более тонкого описания ситуации. Я остановился на пяти состояниях:
      	* (a)	–2 — точно нет
      	* (b)	–1 — скорее нет, чем да
      	* (0)	 0 — нейтральное состояние
      	* (c)	 1 — скорее да, чем нет
      	* (d)	 2 — точно да
 
      Таким образом, каждое из состояний — это не просто бинарный флаг, а некий «регулятор» уровня или интенсивности.

      Кроме того, я решил добавить флаг (f), который будет указывать направление изменения:
            * f = A изменяет значение a
            * f = B изменяет значение b 
            * f = C изменяет значение c 
            * f = D изменяет значение d 
            * f = 0 ничего не изменяет или же обнуляет систему

	Для управления системой я решил использовать входной сигнал v – он будет поступать на вход системы и интерпретироваться как «желание» системы изменить какое-то из своих состояний. Чтобы не ломать общую картину модели, v также находится в диапазоне от -2 до 2.




	И вот на этом месте я «завис».

      Если следовать логике, то теоретически система должна получить некоторый сигнал v. Предположим, что v получает сигнал +1 («скорее да»). Тогда в работу вступает флаг f и указывает, к какому состоянию применять изменение: предположим, f = b. Тогда b становится целью изменения, и значение v применяется к текущему значению b.
      Но в этом случае существуют два возможных варианта развития событий:
          1 – прямое присваивание: значение b заменяется на v (b=v)
          2 – плавное изменение (v добавляется к текущему значению b, но не выходит за пределы допустимого диапазона: b = clamp(b + v, -2, 2))
      После любого из возможных состояний b обновляется, а остальные переменные остаются без изменений.
      
      Пример работы такой логики:
      Допустим:
          a = 0, b = 0, c = 0, d = 0
          флаг f = c
          входной сигнал v = -1
      Результат:
          c = -1
          Остальные переменные (a, b, d) остаются равны 0
      
      Первоначально идея кажется прекрасной: 
            * система допускает больше оттенков смысла, чем бинарная логика.
            * изменения управляемы контекстом через флаг.
            * работает детерминированно, но даёт пространство для гибкости,  
              особенно в принятии решений.
            * можно построить цепочку логики, при которой каждое действие 
              влияет на следующий выбор.
      
      Но этот вариант я отложил в сторону как ограниченный: ведь флаг управляет только одним состоянием, а моя идея заключается в том, чтобы выбор одного флага влиял бы на все состояния сразу! Например,            активация флага «a» позволила бы работать с состояниями «b», «c» и «d», активация флага «b» - с состояниями «a», «c» и «d», и так далее. Например,
            * f = A изменяет значение b, c, d
            * f = B изменяет значение a, c, d 
            * f = C изменяет значение a, b, d 
            * f = D изменяет значение a, b, c 
            * f = 0 ничего не изменяет или же обнуляет систему
            * f = Z изменяет все значения a, b, c, d
            
      В этом случае сигнал (v) может транслироваться не в одну, а в несколько переменных. Более того, каждой из этих переменных в момент изменения можно даже добавить свой вес, чтобы учесть различный               вклад.

      На сегодня - все, логику работы и первый код допишу завтра.



24 июня 2025 года

	Итак, после небольшого отдыха я снова взялся за обдумывание этой безумной идеи, и еще раз пересмотрел ее ключевые особенности:

	1. Исходная система (a/b/c/d, v, f) представляет собой, по сути, базу для 
	   создания векторного состояния. В итоге получается 5-мерное пространство (4 
	   состояния + 1 флаг), в котором каждое состояние можно представить как 
	   векторный элемент.
	2. Модель изменения параметров предполагает два возможных варианта: замену и 
	   инкрементирование. Попробую использовать оба.
	3. Также для работы придется использовать концепцию весов. Например:
			f = A: { b:+1.0, c:+0.5, d:+0.25 }.
	   Таким образом v = -1 будет масштабирован:
		    b_new = b + v * 1.0
		    c_new = c + v * 0.5
		    d_new = d + v * 0.25
	   и это позволит хранить веса прямо в структуре данных для флагов.
	4. Придется поработать с вероятностями: можно хранить не сами дискретные 
	   состояния -2, -1, 0, 1, 2, а вероятность принадлежности состояния 	  
	   (например, вектор из пяти элементов для каждого из a/b/c/d). А на базе 
	   этих векторов можно принимать решение (через argmax),создавать мягкое 
	   голосование,хранить историю изменения для самообучающихся моделей.

	Но сейчас я пойду по самому простому пути, без углублений в дебри всяких высокомудрых сущностей.

	Начальными условиями для реализации моего проекта будут следующие данные:
		* Структура даных для состояния:
				state = {
				    'a': 0,
				    'b': 0,
				    'c': 0,
				    'd': 0
				}
		* Карта флагов:
				flags = {
					'A': {'b': 1.0, 'c': 1.0, 'd': 1.0},
					'B': {'a': 1.0, 'c': 1.0, 'd': 1.0},
					...
				}
		* Реализация обеих моделей изменения: и direct assignment, и incremental 
		  shift
		* Создание отдельного слоя для обработки веса (возможный переход в 
	  	  вероятность)
		* Формирование механизма обучения, чтобы веса флагов не были статическими, а 
		  изменялись в зависимости от обратной связи

	Теперь немного об определении жизнеспособности модели. Для этого я постараюсь учесть несколько принципов:
		* Явный диапазон значений: каждое из состояний не должно выйти за пределы [-2, 2]. Для этого используется clamp()
		* Стабильность: изменения не должны приводить к коллапсу состояния - иными словами нужно ввести механизм проверки, чтобы не было неограниченного накопления (например, постоянный рост a или b)
		* Уникальный результат для комбинации: каждый паттерн должен создавать различимый результат ( (a, b, c) не должно вести к тому же результату, что (a, b, d), чтобы имело смысл создавать 		  разные паттерны).
		* Простота проверки: для проверки модели нужно несколько этапов - задание начальных значений a, b, c, d (для удобства пусть будут нулевыми), задание флага (f) и величины изменения (v) (пусть 		  тоже нулевые), вычисление новых состояний и поиск коллизий или ошибок.


	Механизм определения жизнеспособности модели я реализовал так:

		1. Явный диапазон значений
			Прямо в конце пересчёта состояния я делаю:
				a = clamp(a, -2, 2)
				b = clamp(b, -2, 2)
				c = clamp(c, -2, 2)
				d = clamp(d, -2, 2)
			таким образом гарантируеся стабильный диапазон даже в самых “странных” 		комбинациях.
		
		2. Стабильность
			Я использую простую проверка перед изменением:
				if a < 2 and v > 0:
				    a = a + v_adjusted
				elif a > -2 and v < 0:
				    a = a + v_adjusted
	
		3. Уникальный результат для комбинации
			Здесь я применяю проверку паттернов:
				- задаю несколько начальных комбинаций (a, b, c, d)
				- изменяю состояние для разных флагов и векторов
				- смотрю, различимы ли результирующие комбинации
				- делаю сет результатов:
					results = set()
					results.add((a, b, c, d))
				- проверяю, есть ли уже такая комбинация для другой комбинации f, 			  v, избегая тем самым коллизий
	
		4. Простота проверки
			- задаю начальное состояние (например, a = b = c = d = 0)
			- перебираю все флаги (A, B, C, D, Z) и несколько значений v (-2, -1, 			  0, 1, 2)
			- для каждой комбинации вычисляю новое состояние
		   Проверяю:
			- принадлежность значений диапазону [-2, 2]
			- наличие коллизий
		   Составляю короткий отчет:
			- вывожу количество уникальных комбинаций
			- вывожу количество коллизий


	Реализация 00:
		Выложена в подпапке “Idea” под именем “Idea_00.py”. Успехом не увенчалась: показала следующие данные:
	
	| Всего запусков: 1000000 
	| Уникальных комбинаций: 21 
	| Число случаев, когда хотя бы одна из переменных уперлась в предел: 399884 
	| Доля уникальных комбинаций: 0.00%
	
	Вывод: текущая логика приводит к тому, что
		* состояния очень быстро приходят в крайние значения
		* пространство результатов оказывается крайне бедным
	
	Анализ: я строил программу по принципу «основная цель флага получает весь импульс, остальные — долю». Это показалось мне наиоблее логично. Но проверка показала, что уникальными оказались только 21 из всех возможных вариантов. Думаю, что корень проблемы заключается не в логике, а в её реализации в проверочном коде.
	
	
	На сегодня я заканчиваю и продолжу работу завтра.



25 июня 2025 года

	Сегодня я проанализировал код и вывел следующие особенности, которые, возможно, и привели меня к ошибке:
		* я делал проверки в пределах одного шага
		* каждое испытание начиналось с (a=0, b=0, c=0, d=0).
		* срабатывал лишь один сигнал v для одного флага f.
		* и только после этого результат фиксировался.
	
	Таким образом моя ошибка заключалась в том, что я видел только то, что дают единичные комбинации одного шага, но при этом не видел всего многошагового процесса, раскрывающего потенциал модели.
	
	Исправить свою ошибку я попробовал следующим образом:
		* я не буду сбрасывать состояние в (0,0,0,0) каждый раз, а вести несколько шагов подряд для одного экземпляра – это позволит проверить, как работают накопления в пределах [-2,2].
		* я буду сохранять результат не одного шага, а всей последовательности — тогда разнообразие комбинаций вырастет.
		* я буду дополнительно проверять разные начальные состояния.
	
	
	Реализация 01:
	        Выложена в подпапке “Idea” под именем “Idea_01.py”. Увенчалась относительным успехом: показала следующие данные:
	 
	| Всего запусков цепочек: 100000 
	| Шагов в каждой цепочке: 100 
	| Уникальных комбинаций: 59486 
	| Число случаев, когда хотя бы одна из переменных уперлась в предел: 68117 
	| Доля уникальных комбинаций: 59.49%
	
	Первоначальные данные меня обнадежили: 
	* 59.5% уникальных комбинаций – это, по сути, полноценный спектр состояний. А это значит, что цепочка из 100 шагов раскрывает потенциал модели: из короткого флажка превращается в своего рода 	
 	  пространственное поведение.
	* Количество случаев упора в пределы (68117 из 100000) не критично — это значит, что примерно в двух случаях из трёх состояние движется в пределах диапазона, не блокируясь.
	
	Но дальнейший анализ поведения системы я оставлю на завтра.



26 июня 2025 года

	Решил увеличить количество запусков цепочек, и вместо 100000 поставил 1000000. 
 	Работу проводил, изменив параметр в файле “Idea_01.py”, поэтому выкладывать новый файл не вижу смысла.
  
  	Программа показала следующие данные:

 	| Всего запусков цепочек: 1000000
	| Шагов в каждой цепочке: 100
	| Уникальных комбинаций: 332835
	| Число случаев, когда хотя бы одна из переменных уперлась в предел: 681245
	| Доля уникальных комбинаций: 33.28%

 	На данный момент результат, в целом, логичный, однако требует доработки и анализа. Эту работу я оставлю на завтра.



27 июня 2025 года

	Анализ не проводил и код не писал - был занят изучением булевых литералов и написанием конспекта по основам Python.



28 июня 2025 года

	Я вернулся к анализу результата, и сделал следующие выводы:
		* логика живая: даже в короткой цепочке из 100 шагов есть около трети уникальных комбинаций
		* система не вырождается в несколько фиксированных комбинаций, а это значит, что есть потенциал для создания разнообразного поведения
		* высокий процент упора в пределы (~68%) абсолютно закономерен и связан с ограничением диапазона

	Следующим шагом был мой анализ путей повышения разнообразия “ответов” модели. Я остановился на трех возможных вариантах:
		* либо увеличить диапазоны (например, [-3, 3])
		* либо изменить веса для более деликатного движения
		* либо реализовать механизм затухания или самоцентрирования.

	Я решил сначала ввести следующееправило самоцентрирования: если значение долго остаётся в максимуме, то вероятность того, что в следующем шаге оно начнёт двигаться в другую сторону, немного 		увеличивается. Это позволит уменьшить количество состояной “упора в крайние значения”. Я выбрал эту идею потому, что она позволяет не съедать ресурсы системы, а давать сбалансированную картинку при 	наименьших затратах вычислительных мощностей.

	Реализация 02:
        	Выложена в подпапке “Idea” под именем “Idea_02.py”. Увенчалась относительным успехом: показала следующие данные:
 
	| Всего запусков цепочек: 1000000
	| Шагов в каждой цепочке: 100
	| Уникальных комбинаций: 354883
	| Число случаев, упершихся в предел [-2,2]: 721299
	| Доля уникальных комбинаций: 35.49%
	
	Идея про вероятность смены направления увеличила разнообразие и сделала логику несколько «живее».
 


29 июня 2025 года

	Я пересмотрел результат, протестировал программу несколько раз и окончательно убедился в том, что залипания происходят примерно в 70% случаев. Такое количество залипаний мне очень сильно не 		понравилось, и я решил проанализировать код. 
	
	Я ввел переменную stick_count, чтобы при залипании на границах с некоторой вероятностью изменить направление (v = -v), и посчитал, что эта идея решит мою проблему, однако эта логика в моем коде 
 	работает после того, как v уже выбран и применяется ко всем весам, то есть:

			v = random.randint(-2, 2)
			f = random.choice(list(weights.keys()))
			for key, weight in weights[f].items():
			    new_value = state[key] + v * weight
			    if state[key] in [-2, 2]:
			        stick_count[key] += 1
			        if random.random() < stick_count[key] * 0.1:
			            v = -v
			    state[key] = clamp(new_value)

	Иными словами, v меняется во время цикла, но он уже применен к нескольким переменным в текущем флаге f. 

	Таким образом, получается следующая ситуация: если первая переменная уже на границе, она триггерит инверсию v = -v, и тогда следующая переменная, которая ещё не на границе, получает уже изменённый 
 	v. Но при этом stick_count у всех суммируется, и это может перевернуть v несколько раз в одном проходе (в непредсказуемый момент), нарушая консистентность между входом и действием!

	И решить эту задачу я попытаюсь следующим образом: 
		* попробую выяснить, какие из переменных "прилипли"
		* на основе этих переменных решу, инвертировать ли v
		* применю v ко всем переменным
	
 	Реализация 03:
        	Выложена в подпапке “Idea” под именем “Idea_03.py”. Показала следующие данные:

	| Всего запусков цепочек: 1000000
	| Шагов в каждой цепочке: 100
	| Уникальных комбинаций: 332856
	| Число случаев, упершихся в предел [-2,2]: 681161
	| Доля уникальных комбинаций: 33.29% 
 
  	Ситуация ухудшилась - в прошлый раз уникальных комбинаций было 35,49%.

   
   	Парадоксальная ситуация (сравнение результатов "до" и "после" изменения v):
 
 	Версия				Уникальных комбинаций		Упоров в предел		Доля
	До (v менялся в процессе)	354 883				721 299			35.49%
	После (v меняется заранее)	332 856				681 161			33.29%

    
    	Раньше v двигался "хаотично", что увеличивало разброс, а теперь v стабилен и движение стало более предсказуемым, но при этом чаще попадает в те же комбинации, особенно если веса не способствуют 	разнообразию. Иными словами:
     			* первый результат более разнообразен, но менее контролируем
			* второй результат чище, но однообразнее


	Решение этой проблемы я оставлю на завтра.
 


30 июня 2025 года

	Очередной анализ поведения модели привел меня к следующему выводу: я все время использую одни и те же коэффициенты
	'A': {'b': 1.0, 'c': 0.5, 'd': 0.25}, 
	что не позволяет добиться вариативности. Поэтому я предприму следующие шаги для улучшения ситуации:
		* попробую варьировать коэффициенты:
			def noisy_weight(base, noise=0.1):
				return base + random.uniform(-noise, noise)
			...
			actual_weight = noisy_weight(base_weight)

		* добавлю "затухание" к центру - при каждом шаге буду понемногу смещать a, b, c, d к нулю. Это не даст системе "залипать" в крайностях, и может создать больше разнообразия: 
			for key in state:
				state[key] *= 0.98  # медленное возвращение к нулю

    	Реализация 04:
        	Выложена в подпапке “Idea” под именем “Idea_04.py”. Показала следующие данные:

	| Всего запусков цепочек: 1000000
	| Шагов в каждой цепочке: 100
	| Уникальных комбинаций: 948622
	| Число случаев, упершихся в предел [-2,2]: 612379
	| Доля уникальных комбинаций: 94.86%

	Количество уникальных комбинаций несколько увеличилось Этот результат оказался достижим благодаря введению динамических весов, которые сделали систему
 		* нелинейной — при каждом шаге меняется реакция на сигнал
		* непредсказуемой, но в рамках логики — веса напоминают оригинальные, но не совпадают с ними
  		* менее склонной к залипанию — один и тот же сигнал теперь не обязательно «добьёт» до предела

    	Таким образом, на текущий момент мной создана система, имеющая следующие возможности:
    		* обучаемость (если добавить изменение весов на основе результата)
		* реактивность (уже сейчас система реагирует на перегруз),
		* разнообразность (94% уникальных комбинаций)
		* может стать ядром ИИ-модуля или поведения NPC, нейронки, осмысленного агента.

	Дальнейшую работу с моделью оставлю на завтра.
 


01 июля 2025 года
		
	Понятия не имею, как добиться отсутствия залипаний. 
	
	Я задался двумя вопросами:
		* можно ли изначально все базовые веса ставить в 0? 
		  Теоретически, это позволит нам более "чисто" смотреть на результат эксперимента, поскольку система будет стартовать из состояния покоя. 
		* почему бы и базовые веса в таком случае не сделать "рандомными"?
	
	Если следовать логике, то система в таком случае будет работать по следующим принципам:
		* система стартует из абсолютного покоя, все ее флаги сначала «немые». Значит, модель чиста, как белый лист
		* вес сам нарастает (или задаётся случайно)	Это похоже на работу нервной системы, которая только учится реагировать на раздражители
		* отсутствует заранее прошитая логика - модель не "знает" изначально, а учится сама
		* любые реакции модели - это результат самого кода, а не скрытой предвзятости
	
	Но, думаю, могут возникнуть подводные камни:
		* если все веса будут иметь нулевые значения, то, возможно, система не станет меняться
		* если веса будут слишком случайны, то система будет хаотична
		* результаты могут очень сильно изменяться при каждом запуске
	
	Итак, предварительные действия:
	1. Обнуляем базовые веса:
			base_weights = {
				'A': {},
				'B': {},
				'C': {},
				'D': {},
				'Z': {}
			}
	2. Генерируем случайные веса при старте программы - так каждый запуск создаёт свою карту влияний:
			def generate_random_weights():
				weights = {}
				for flag in ['A', 'B', 'C', 'D', 'Z']:
					affected_keys = [k for k in ['a', 'b', 'c', 'd'] if random.random() < 0.75]  # каждый флаг влияет не на всё
					weights[flag] = {k: round(random.uniform(0.1, 1.0), 2) for k in affected_keys}
				return weights
			# Пример
			base_weights = generate_random_weights()
	
	
	Вообще, дать возможность системе самой определить свое поведение - шаг, мягко говоря, неумный. Но посмотрим, что из этого получится.
	
	Реализация 05:
	    	Выложена в подпапке “Idea” под именем “Idea_05.py”. Показала следующие данные:
	
	| Случайно сгенерированные веса:
	|   A: {'b': 0.17, 'c': 0.97}
	|   B: {'b': 0.21, 'c': 0.17, 'd': 0.23}
	|   C: {'a': 0.96, 'b': 0.2}
	|   D: {'b': 0.45, 'd': 0.53, 'a': 0.38, 'c': 0.6}
	|   Z: {'a': 0.52}
	
	| РЕЗУЛЬТАТ ЭКСПЕРИМЕНТА
	| Всего запусков цепочек: 1000000
	| Шагов в каждой цепочке: 100
	| Уникальных комбинаций: 975512
	| Число случаев, упершихся в предел [-2,2]: 569956
	| Доля уникальных комбинаций: 97.55%
	
	
	На основе результатов эксперимента можно сделать следующие выводы:
		* система не повторяется
		* система явно имеет свой "характер"
		* система не "живет" в границах [-2,2]
	
	Дальнейшие рассуждения о развитии модели оставлю на завтра.
 
 СРОЧНОЕ ОБНОВЛЕНИЕ

  В РЕЗУЛЬТАТЕ ВЫХОДА ИЗ СТРОЯ ЖЕСТКОГО ДИСКА И УТЕРИ ВСЕЙ ИНФОРМАЦИИ, РАБОТА ПРИОСТАНАВЛИВАЕТСЯ НА НЕОПРЕДЕЛЕННЫЙ СРОК.
 


02 июля 2025 года

	К сожалению, в 57% случаев система залипает, что представляет собой серьезную проблему
	для дальнейшего развития модели. Причин этому, как я полагаю, три:
		* накопительный эффект:
			например, если флаг "C" влияет на a с весом 0.96, а модель 5 раз подряд получает
			v = 2, то a += 2 * 0.96 = 1.92  → почти 2. Как результат - ещё один шаг -
			и модель уже в +2 → дольше остаюсь в «залипшем» виде.
		* отсутствие возвратак нулевым значениям:
			у модели есть движения вверх и вниз, но нет механизма, который  бы "останавливал"
			ее, когда она застревает.
		* "смещения" случайных весов:
			вероятности неисповедимы, и вполне возможны такие конфигурации флагов, где
			большинство влияет в одну сторону.

	Направлений решения этой задачи я вижу два: либо самоцентрирование, либо гравитация к нулю.

	* самоцентрирование:
		можно ввести три дополнительных правила:
			- сила затухнания (damping) - уменьшает силу сигнала, если переменная близка к
			  краю
			- самоцентрирование - при каждом шаге создается маленькое условие для
			  самостоятельного возврата переменной к нулю
			- контр-импульс - если, например, переменная а застряла в +2, то следующая
			  следующая реакция будет работать в "минус" с большей вероятностью
		Пример кода:
			for key in state:
				if state[key] == 2 and random.random() < 0.05:
					state[key] -= 0.5
				elif state[key] == -2 and random.random() < 0.05:
					state[key] += 0.5
		Такой вариант мягко ослабляет залипание, используя не силу входного сигнала,
		а внутренний механизм "возврата к балансу".

	* гравитация к нулю:
			for key in state:
				if state[key] > 0:
					state[key] -= 0.1
				elif state[key] < 0:
					state[key] += 0.1
		Такой вариант не разрушит случайность, но сделает её менее застревающей.

	Я решил пойти путем создания "живой" модели с динамическим самоцентрированием.
	Причина проста: любая гомеостатическая система не предполагает "жесткой гравитации".
	
	Теперь моя задача - создать "живую" систему, в которой:
		* залипание возможно, но очень невыгодно
	    * при долгих перекосах растёт шанс сдвига обратно
		* центрирование работает мягко, используя вероятность
	
	Принцип самоцентрирования я реализую следующим образом:
		если переменная "застряла" в "-2" или "2", то начинаем считать,
		сколько шагов она там сидит. Чем дольше сидит, тем выше шанс на импульс
		в противоположную сторону. Если импульс сработал — инвертирую v или ослабляю накопление.
	
	Реализация 06:
	    	Выложена в подпапке “Idea” под именем “Idea_06.py”. Показала следующие данные:
	
	Случайно сгенерированные веса:
	  A: {'c': 0.92, 'a': 0.26}
	  B: {'d': 0.11, 'c': 0.59, 'a': 0.73}
	  C: {'c': 0.27, 'd': 0.75, 'a': 0.56, 'b': 0.12}
	  D: {'a': 0.76}
	  Z: {'c': 0.82, 'd': 0.15}
	
	| РЕЗУЛЬТАТ ЭКСПЕРИМЕНТА
	| Всего запусков цепочек: 1000000
	| Шагов в каждой цепочке: 100
	| Уникальных комбинаций: 999145
	| Число случаев, упершихся в предел [-2,2]: 544858
	| Доля уникальных комбинаций: 99.91%
	
	
	Вывод:
		* система практически перестала повторяться
		* самоцентрирование сработало как встроенная биологическая регуляция
		* количество залипаний снижается, но не исчезает
	
	В адаптивных, сложных живых моделях (вроде биологических сетей, когнитивных симуляций
	или поведенческих ИИ) состояние либо не доходит до крайностей, либо, если доходит —
	немедленно компенсируется. А у меня высокий процент "залипаний". Причины этому, как я вижу,
	нужно искать в моей текущей реализации: ни случайные веса, ни самоцентрирование, ни
	ограничение диапазона не дают системе “понимания”, что она застряла - модель просто реагирует,
	не анализируя своё состояние в контексте.
	
	Решением этой задачи я займусь завтра.
